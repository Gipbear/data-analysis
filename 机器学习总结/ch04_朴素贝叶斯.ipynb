{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯 Naive Bayes\n",
    "\n",
    "朴素贝叶斯主要是可以用来解决逆向概率，基本原理是：对于给出的待分类项，求解在各个类别下发生的概率，哪个条件下发生的概率最大则分为哪个类别。\n",
    "\n",
    "* 正项概率：已知袋子里有N个黑球和M个白球，求拿出白球的概率。\n",
    "* 逆向概率：从袋子摸出几个球，求袋子里黑球和白球的比例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯原理\n",
    "\n",
    "贝叶斯定理是用来描述两个条件概率之间关系的，可以将两个条件概率相互转换：\n",
    "\n",
    "$$\n",
    "    P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "之所以说该算法朴素，是因为假定所有特征在数据集中`同等重要且独立`。\n",
    "\n",
    "1. 我们假设每个数据样本都用n维特征向量$\\{a_1, a_2, \\cdots, a_n\\}$来表示，用来描述对n个条件属性{$\\pmb{A}_1, \\pmb{A}_2, \\cdots, \\pmb{A}_n$}的n个度量，同时假设类变量$\\pmb{C} = \\{C_1, C_2, \\cdots, C_m\\}$。\n",
    "2. 给定未知的数据样本$\\pmb{X}$(即没有分好的类标签)，计算所有类标签$C_i$的后验假设$P(C_i|\\pmb{X})$，最大值的类标签就是样本$\\pmb{X}$的标签。\n",
    "3. 根据贝叶斯定理可得：\n",
    "    \n",
    "    $$\n",
    "        P(C_i|\\pmb{X}) = \\frac{P(\\pmb{X}|C_i)P(C_i)}{P(\\pmb{X})}\n",
    "    $$\n",
    "    \n",
    "    其中$P(\\pmb{X})$对于所有的类为常数，称为**证据因子**，用于使得所有的类的先验概率之和为1。通常来说，若类$P(C_i)$的先验概率未知，则一般假设这些**概率相等**，或者还可以使用类$C_i$的训练样本数占训练样本的总数的比例进行计算。\n",
    "4. 计算$P(\\pmb{X}|C_i)$的过程为：\n",
    "    \n",
    "    $$\n",
    "        P(\\pmb{X}|C_i) = \\prod^n_{k=1}P(a_k | C_i)\n",
    "    $$\n",
    "    \n",
    "    其中的$P(a_k | C_i)$可以使用训练样本估计求出。\n",
    "    * 若$A_k$是离散属性，则使用$P(a_k | C_i) = s_{ik}/s_i$，其中$s_{ik}$是在属性$A_k$上具有值$a_k$的类$C_i$的训练样本数，$s_i$是$C_i$中的训练样本数。\n",
    "    * 若$A_k$是连续属性值，通常假设该属性**服从高斯分布**。\n",
    "5. 总的来说，朴素贝叶斯分类模型的数学表述为：\n",
    "    $$\n",
    "        C_{NBC} = arg \\quad \\max_{C_i∈C} P(C_i)\\prod^m_{k=1}P(a_k | C_i)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯的特点\n",
    "\n",
    "* 优势\n",
    "    * 算法形式简单易懂，可解释性强。\n",
    "    * 朴素贝叶斯消耗时间空间代价较小。\n",
    "* 劣势\n",
    "    * 算法假设属性特征之间相互独立，而现实中属性特征之间往往相关性较强。\n",
    "    * 算法将各个属性特征对分类的影响程度视为相同。\n",
    "    * 对于有序分类变量等会造成有效信息的损失。\n",
    "\n",
    "* 改进\n",
    "    * 对于属性之间相互独立问题，提出半朴素贝叶斯模型，根据属性之间的相关程度，将属性划分为几个有交集的小组，使得各小组相互独立。\n",
    "    * 对于算法将属性重要程度视作相同的情况，提出属性加权朴素贝叶斯分类算法，增加权重来调整贝叶斯算法。\n",
    "    * 还要朴素被贝叶斯树，将决策树与朴素贝叶斯相结合，在决策树的每一个节点构建一个朴素贝叶斯分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn中的朴素贝叶斯\n",
    "sklearn 提供了3个朴素贝叶斯分类算法，分别是高斯朴素贝叶斯（GaussianNB）、多项式朴素贝叶斯（MultinomialNB）和伯努利朴素贝叶斯（BernoulliNB）。\n",
    "\n",
    "* GaussianNB：特征变量是`连续变量`，符合高斯分布，比如说人的身高，物体的长度。\n",
    "* MultinomialNB：特征变量是`离散变量`，符合多项分布，在文档分类中以单词为粒度，特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。\n",
    "* BernoulliNB：特征变量是`布尔变量`，符合 0/1 分布，在文档分类中以文件为粒度，特征变量是单词是否出现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))  # 对样本进行增量拟合\n",
    "print(clf_pf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "X = rng.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(X[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "X = rng.randint(5, size=(6, 100))\n",
    "Y = np.array([1, 2, 3, 4, 4, 5])\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict(X[2:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
